{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fee4b3b-d06a-44c5-a58d-aab474ae210c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR PDF Processing Code\n",
    "# Complete implementation for reading OCR scanned PDF files using PIL and related libraries\n",
    "\n",
    "# Required Libraries Installation:\n",
    "# pip install Pillow pytesseract pdf2image opencv-python numpy\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from PIL import Image, ImageEnhance, ImageFilter, ImageOps\n",
    "from pdf2image import convert_from_path\n",
    "from datetime import datetime\n",
    "\n",
    "# Windows users may need to specify tesseract path\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# ========== BASIC PDF OCR FUNCTIONS ==========\n",
    "\n",
    "def simple_pdf_ocr(pdf_path):\n",
    "    \"\"\"\n",
    "    Basic PDF OCR with minimal preprocessing\n",
    "    \"\"\"\n",
    "    # Convert PDF to images\n",
    "    pages = convert_from_path(pdf_path, dpi=300)\n",
    "    \n",
    "    extracted_text = []\n",
    "    \n",
    "    for page_num, page in enumerate(pages):\n",
    "        # Convert to PIL Image and perform OCR\n",
    "        text = pytesseract.image_to_string(page)\n",
    "        extracted_text.append(f\"=== Page {page_num + 1} ===\\n{text}\\n\")\n",
    "    \n",
    "    return \"\\n\".join(extracted_text)\n",
    "\n",
    "def enhanced_pdf_ocr(pdf_path, output_folder=None):\n",
    "    \"\"\"\n",
    "    Enhanced PDF OCR with PIL image preprocessing\n",
    "    \"\"\"\n",
    "    # Convert PDF to images with high DPI for better quality\n",
    "    pages = convert_from_path(pdf_path, dpi=300, fmt='png')\n",
    "    \n",
    "    extracted_text = []\n",
    "    \n",
    "    for page_num, page in enumerate(pages):\n",
    "        # Save original if output folder specified\n",
    "        if output_folder:\n",
    "            os.makedirs(output_folder, exist_ok=True)\n",
    "            page.save(f\"{output_folder}/page_{page_num + 1}_original.png\")\n",
    "        \n",
    "        # Preprocess the image\n",
    "        processed_page = preprocess_image_for_ocr(page)\n",
    "        \n",
    "        # Save processed image\n",
    "        if output_folder:\n",
    "            processed_page.save(f\"{output_folder}/page_{page_num + 1}_processed.png\")\n",
    "        \n",
    "        # Perform OCR with custom configuration\n",
    "        custom_config = r'--oem 3 --psm 6'\n",
    "        text = pytesseract.image_to_string(processed_page, config=custom_config)\n",
    "        \n",
    "        extracted_text.append(f\"=== Page {page_num + 1} ===\\n{text}\\n\")\n",
    "    \n",
    "    return \"\\n\".join(extracted_text)\n",
    "\n",
    "# ========== IMAGE PREPROCESSING FUNCTIONS ==========\n",
    "\n",
    "def preprocess_image_for_ocr(image):\n",
    "    \"\"\"\n",
    "    Preprocess image using PIL to improve OCR accuracy\n",
    "    \"\"\"\n",
    "    # Convert to grayscale\n",
    "    if image.mode != 'L':\n",
    "        image = image.convert('L')\n",
    "    \n",
    "    # Enhance contrast\n",
    "    enhancer = ImageEnhance.Contrast(image)\n",
    "    image = enhancer.enhance(2.0)\n",
    "    \n",
    "    # Enhance sharpness\n",
    "    enhancer = ImageEnhance.Sharpness(image)\n",
    "    image = enhancer.enhance(1.5)\n",
    "    \n",
    "    # Apply noise reduction\n",
    "    image = image.filter(ImageFilter.MedianFilter(size=3))\n",
    "    \n",
    "    # Convert to numpy array for advanced processing\n",
    "    img_array = np.array(image)\n",
    "    \n",
    "    # Apply adaptive threshold for better text separation\n",
    "    img_array = cv2.adaptiveThreshold(\n",
    "        img_array, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "        cv2.THRESH_BINARY, 11, 2\n",
    "    )\n",
    "    \n",
    "    # Convert back to PIL Image\n",
    "    return Image.fromarray(img_array)\n",
    "\n",
    "def advanced_image_preprocessing(image):\n",
    "    \"\"\"\n",
    "    Advanced image preprocessing for better OCR results\n",
    "    \"\"\"\n",
    "    # Convert to grayscale if needed\n",
    "    if image.mode != 'L':\n",
    "        image = image.convert('L')\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    img_array = np.array(image)\n",
    "    \n",
    "    # 1. Noise reduction\n",
    "    img_array = cv2.medianBlur(img_array, 3)\n",
    "    \n",
    "    # 2. Gaussian blur to smooth\n",
    "    img_array = cv2.GaussianBlur(img_array, (1, 1), 0)\n",
    "    \n",
    "    # 3. Adaptive thresholding for better text separation\n",
    "    img_array = cv2.adaptiveThreshold(\n",
    "        img_array, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "        cv2.THRESH_BINARY, 11, 2\n",
    "    )\n",
    "    \n",
    "    # 4. Morphological operations to clean up\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    img_array = cv2.morphologyEx(img_array, cv2.MORPH_CLOSE, kernel)\n",
    "    img_array = cv2.morphologyEx(img_array, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    # Convert back to PIL Image\n",
    "    processed_image = Image.fromarray(img_array)\n",
    "    \n",
    "    # 5. PIL-specific enhancements\n",
    "    # Enhance contrast\n",
    "    enhancer = ImageEnhance.Contrast(processed_image)\n",
    "    processed_image = enhancer.enhance(1.2)\n",
    "    \n",
    "    # Enhance sharpness\n",
    "    enhancer = ImageEnhance.Sharpness(processed_image)\n",
    "    processed_image = enhancer.enhance(1.5)\n",
    "    \n",
    "    return processed_image\n",
    "\n",
    "def rotate_image_if_needed(image):\n",
    "    \"\"\"\n",
    "    Detect and correct image rotation using PIL\n",
    "    \"\"\"\n",
    "    # Convert to numpy for rotation detection\n",
    "    img_array = np.array(image)\n",
    "    \n",
    "    # Use OpenCV to detect text orientation\n",
    "    try:\n",
    "        coords = np.column_stack(np.where(img_array > 0))\n",
    "        angle = cv2.minAreaRect(coords)[-1]\n",
    "        \n",
    "        if angle < -45:\n",
    "            angle = -(90 + angle)\n",
    "        else:\n",
    "            angle = -angle\n",
    "            \n",
    "        # Rotate image using PIL\n",
    "        if abs(angle) > 1:  # Only rotate if significant angle\n",
    "            image = image.rotate(angle, expand=True, fillcolor='white')\n",
    "    except:\n",
    "        pass  # Skip rotation if detection fails\n",
    "    \n",
    "    return image\n",
    "\n",
    "def process_different_image_types(image):\n",
    "    \"\"\"\n",
    "    Handle different types of scanned documents\n",
    "    \"\"\"\n",
    "    # Get image statistics\n",
    "    extrema = image.getextrema()\n",
    "    \n",
    "    if image.mode == 'RGB':\n",
    "        # Color image - convert to grayscale smartly\n",
    "        # Check if it's already mostly grayscale\n",
    "        r_range = extrema[0][1] - extrema[0][0]\n",
    "        g_range = extrema[1][1] - extrema[1][0]\n",
    "        b_range = extrema[2][1] - extrema[2][0]\n",
    "        \n",
    "        if max(r_range, g_range, b_range) < 50:\n",
    "            # Already mostly grayscale\n",
    "            image = image.convert('L')\n",
    "        else:\n",
    "            # Convert using luminance\n",
    "            image = image.convert('L')\n",
    "    \n",
    "    # Handle very dark or very light images\n",
    "    if image.mode == 'L':\n",
    "        min_val, max_val = extrema\n",
    "        \n",
    "        if max_val - min_val < 50:  # Low contrast\n",
    "            # Enhance contrast significantly\n",
    "            enhancer = ImageEnhance.Contrast(image)\n",
    "            image = enhancer.enhance(3.0)\n",
    "        \n",
    "        # Auto-level using PIL\n",
    "        image = ImageOps.autocontrast(image)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# ========== OCR CONFIGURATION FUNCTIONS ==========\n",
    "\n",
    "def ocr_with_custom_config(image, lang='eng'):\n",
    "    \"\"\"\n",
    "    OCR with custom Tesseract configuration\n",
    "    \"\"\"\n",
    "    # Different PSM modes for different document types\n",
    "    configs = {\n",
    "        'single_block': r'--oem 3 --psm 6',  # Single uniform block\n",
    "        'single_line': r'--oem 3 --psm 7',   # Single text line\n",
    "        'single_word': r'--oem 3 --psm 8',   # Single word\n",
    "        'sparse_text': r'--oem 3 --psm 11',  # Sparse text\n",
    "        'auto': r'--oem 3 --psm 3'           # Auto page segmentation\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for config_name, config in configs.items():\n",
    "        try:\n",
    "            text = pytesseract.image_to_string(\n",
    "                image, \n",
    "                lang=lang, \n",
    "                config=config\n",
    "            )\n",
    "            results[config_name] = text\n",
    "        except Exception as e:\n",
    "            results[config_name] = f\"Error: {str(e)}\"\n",
    "    \n",
    "    return results\n",
    "\n",
    "def get_ocr_confidence(image):\n",
    "    \"\"\"\n",
    "    Get OCR confidence scores\n",
    "    \"\"\"\n",
    "    data = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)\n",
    "    \n",
    "    confidences = [int(conf) for conf in data['conf'] if int(conf) > 0]\n",
    "    \n",
    "    if confidences:\n",
    "        avg_confidence = sum(confidences) / len(confidences)\n",
    "        return avg_confidence, confidences\n",
    "    else:\n",
    "        return 0, []\n",
    "\n",
    "def multilingual_ocr(image, languages=['eng', 'spa', 'fra']):\n",
    "    \"\"\"\n",
    "    Try OCR with multiple languages\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for lang in languages:\n",
    "        try:\n",
    "            text = pytesseract.image_to_string(image, lang=lang)\n",
    "            confidence, _ = get_ocr_confidence(image)\n",
    "            results[lang] = {\n",
    "                'text': text,\n",
    "                'confidence': confidence\n",
    "            }\n",
    "        except Exception as e:\n",
    "            results[lang] = {\n",
    "                'text': '',\n",
    "                'confidence': 0,\n",
    "                'error': str(e)\n",
    "            }\n",
    "    \n",
    "    # Return result with highest confidence\n",
    "    best_lang = max(results.keys(), key=lambda x: results[x]['confidence'])\n",
    "    return results[best_lang]['text'], results\n",
    "\n",
    "# ========== SPECIALIZED DOCUMENT PROCESSING ==========\n",
    "\n",
    "def extract_table_from_image(image):\n",
    "    \"\"\"\n",
    "    Extract tables from images using PIL preprocessing\n",
    "    \"\"\"\n",
    "    # Convert to grayscale\n",
    "    if image.mode != 'L':\n",
    "        image = image.convert('L')\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    img_array = np.array(image)\n",
    "    \n",
    "    # Detect horizontal and vertical lines\n",
    "    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 1))\n",
    "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 25))\n",
    "    \n",
    "    # Detect lines\n",
    "    horizontal_lines = cv2.morphologyEx(img_array, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "    vertical_lines = cv2.morphologyEx(img_array, cv2.MORPH_OPEN, vertical_kernel)\n",
    "    \n",
    "    # Combine lines\n",
    "    table_structure = cv2.addWeighted(horizontal_lines, 0.5, vertical_lines, 0.5, 0.0)\n",
    "    \n",
    "    # Convert back to PIL\n",
    "    table_image = Image.fromarray(table_structure)\n",
    "    \n",
    "    # OCR with table-specific configuration\n",
    "    table_text = pytesseract.image_to_string(\n",
    "        table_image, \n",
    "        config=r'--oem 3 --psm 6 -c preserve_interword_spaces=1'\n",
    "    )\n",
    "    \n",
    "    return table_text\n",
    "\n",
    "def process_handwritten_text(image):\n",
    "    \"\"\"\n",
    "    Preprocess images for handwritten text OCR\n",
    "    \"\"\"\n",
    "    # Convert to grayscale\n",
    "    if image.mode != 'L':\n",
    "        image = image.convert('L')\n",
    "    \n",
    "    # Enhance contrast more aggressively for handwriting\n",
    "    enhancer = ImageEnhance.Contrast(image)\n",
    "    image = enhancer.enhance(2.5)\n",
    "    \n",
    "    # Apply slight blur to smooth pen strokes\n",
    "    image = image.filter(ImageFilter.GaussianBlur(radius=0.5))\n",
    "    \n",
    "    # Use specialized OCR configuration for handwriting\n",
    "    handwritten_config = r'--oem 3 --psm 8 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
    "    \n",
    "    text = pytesseract.image_to_string(image, config=handwritten_config)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# ========== MAIN PDF PROCESSOR CLASS ==========\n",
    "\n",
    "class PDFOCRProcessor:\n",
    "    def __init__(self, tesseract_path=None):\n",
    "        if tesseract_path:\n",
    "            pytesseract.pytesseract.tesseract_cmd = tesseract_path\n",
    "        \n",
    "        self.processed_pages = []\n",
    "        self.processing_stats = {}\n",
    "    \n",
    "    def process_pdf(self, pdf_path, output_dir=None, languages=['eng']):\n",
    "        \"\"\"\n",
    "        Complete PDF processing pipeline\n",
    "        \"\"\"\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Create output directory\n",
    "        if output_dir:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Convert PDF to images\n",
    "        try:\n",
    "            pages = convert_from_path(pdf_path, dpi=300, fmt='png')\n",
    "        except Exception as e:\n",
    "            return f\"Error converting PDF: {str(e)}\"\n",
    "        \n",
    "        extracted_text = []\n",
    "        page_stats = []\n",
    "        \n",
    "        for page_num, page in enumerate(pages):\n",
    "            print(f\"Processing page {page_num + 1}/{len(pages)}\")\n",
    "            \n",
    "            # Process single page\n",
    "            page_result = self.process_single_page(\n",
    "                page, page_num + 1, output_dir, languages\n",
    "            )\n",
    "            \n",
    "            extracted_text.append(page_result['text'])\n",
    "            page_stats.append(page_result['stats'])\n",
    "        \n",
    "        # Compile results\n",
    "        processing_time = datetime.now() - start_time\n",
    "        \n",
    "        results = {\n",
    "            'pdf_path': pdf_path,\n",
    "            'total_pages': len(pages),\n",
    "            'processing_time': str(processing_time),\n",
    "            'extracted_text': \"\\n\".join(extracted_text),\n",
    "            'page_stats': page_stats\n",
    "        }\n",
    "        \n",
    "        # Save results\n",
    "        if output_dir:\n",
    "            with open(f\"{output_dir}/ocr_results.json\", 'w') as f:\n",
    "                json.dump(results, f, indent=2)\n",
    "            \n",
    "            with open(f\"{output_dir}/extracted_text.txt\", 'w') as f:\n",
    "                f.write(results['extracted_text'])\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def process_single_page(self, page, page_num, output_dir, languages):\n",
    "        \"\"\"\n",
    "        Process a single page with comprehensive preprocessing\n",
    "        \"\"\"\n",
    "        # Save original\n",
    "        if output_dir:\n",
    "            page.save(f\"{output_dir}/page_{page_num:03d}_original.png\")\n",
    "        \n",
    "        # Preprocess image\n",
    "        processed_page = self.comprehensive_preprocessing(page)\n",
    "        \n",
    "        # Save processed\n",
    "        if output_dir:\n",
    "            processed_page.save(f\"{output_dir}/page_{page_num:03d}_processed.png\")\n",
    "        \n",
    "        # Perform OCR\n",
    "        ocr_results = multilingual_ocr(processed_page, languages)\n",
    "        text, lang_results = ocr_results\n",
    "        \n",
    "        # Calculate statistics\n",
    "        stats = {\n",
    "            'page_number': page_num,\n",
    "            'original_size': page.size,\n",
    "            'processed_size': processed_page.size,\n",
    "            'character_count': len(text),\n",
    "            'word_count': len(text.split()),\n",
    "            'language_results': lang_results\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'text': f\"=== Page {page_num} ===\\n{text}\\n\",\n",
    "            'stats': stats\n",
    "        }\n",
    "    \n",
    "    def comprehensive_preprocessing(self, image):\n",
    "        \"\"\"\n",
    "        Apply all preprocessing techniques\n",
    "        \"\"\"\n",
    "        # Step 1: Basic PIL preprocessing\n",
    "        image = process_different_image_types(image)\n",
    "        \n",
    "        # Step 2: Rotation correction\n",
    "        image = rotate_image_if_needed(image)\n",
    "        \n",
    "        # Step 3: Advanced preprocessing\n",
    "        image = advanced_image_preprocessing(image)\n",
    "        \n",
    "        return image\n",
    "\n",
    "# ========== ERROR HANDLING AND OPTIMIZATION ==========\n",
    "\n",
    "def safe_pdf_ocr(pdf_path, max_retries=3):\n",
    "    \"\"\"\n",
    "    PDF OCR with comprehensive error handling\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Check if file exists and is readable\n",
    "            if not os.path.exists(pdf_path):\n",
    "                raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
    "            \n",
    "            # Check file size\n",
    "            file_size = os.path.getsize(pdf_path)\n",
    "            if file_size > 50 * 1024 * 1024:  # 50MB limit\n",
    "                print(f\"Warning: Large file ({file_size/1024/1024:.1f}MB), processing may be slow\")\n",
    "            \n",
    "            # Convert PDF\n",
    "            pages = convert_from_path(pdf_path, dpi=200)  # Lower DPI for large files\n",
    "            \n",
    "            if not pages:\n",
    "                raise ValueError(\"No pages found in PDF\")\n",
    "            \n",
    "            # Process pages\n",
    "            extracted_text = []\n",
    "            for page_num, page in enumerate(pages):\n",
    "                try:\n",
    "                    # Process with timeout-like behavior\n",
    "                    processed_page = preprocess_image_for_ocr(page)\n",
    "                    text = pytesseract.image_to_string(processed_page)\n",
    "                    extracted_text.append(f\"=== Page {page_num + 1} ===\\n{text}\\n\")\n",
    "                except Exception as page_error:\n",
    "                    print(f\"Error processing page {page_num + 1}: {str(page_error)}\")\n",
    "                    extracted_text.append(f\"=== Page {page_num + 1} ===\\n[Error processing page]\\n\")\n",
    "            \n",
    "            return \"\\n\".join(extracted_text)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                return f\"Failed to process PDF after {max_retries} attempts: {str(e)}\"\n",
    "            \n",
    "            # Wait before retry\n",
    "            time.sleep(2 ** attempt)\n",
    "\n",
    "def process_large_pdf(pdf_path, batch_size=5):\n",
    "    \"\"\"\n",
    "    Process large PDFs in batches to manage memory\n",
    "    \"\"\"\n",
    "    # Get total page count first\n",
    "    import subprocess\n",
    "    try:\n",
    "        result = subprocess.run(['pdfinfo', pdf_path], capture_output=True, text=True)\n",
    "        total_pages = int([line for line in result.stdout.split('\\n') if 'Pages:' in line][0].split()[-1])\n",
    "    except:\n",
    "        # Fallback: convert entire PDF to get page count\n",
    "        pages = convert_from_path(pdf_path, dpi=72)  # Low DPI for counting\n",
    "        total_pages = len(pages)\n",
    "        del pages\n",
    "    \n",
    "    extracted_text = []\n",
    "    \n",
    "    # Process in batches\n",
    "    for start_page in range(1, total_pages + 1, batch_size):\n",
    "        end_page = min(start_page + batch_size - 1, total_pages)\n",
    "        \n",
    "        # Convert only current batch\n",
    "        pages = convert_from_path(\n",
    "            pdf_path, \n",
    "            dpi=300, \n",
    "            first_page=start_page, \n",
    "            last_page=end_page\n",
    "        )\n",
    "        \n",
    "        # Process batch\n",
    "        for page_num, page in enumerate(pages):\n",
    "            processed_page = preprocess_image_for_ocr(page)\n",
    "            text = pytesseract.image_to_string(processed_page)\n",
    "            extracted_text.append(f\"=== Page {start_page + page_num} ===\\n{text}\\n\")\n",
    "        \n",
    "        # Clear memory\n",
    "        del pages\n",
    "        \n",
    "        print(f\"Processed pages {start_page}-{end_page}/{total_pages}\")\n",
    "    \n",
    "    return \"\\n\".join(extracted_text)\n",
    "\n",
    "# ========== USAGE EXAMPLES ==========\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Example usage of the OCR PDF processing functions\n",
    "    \"\"\"\n",
    "    # Example 1: Simple PDF OCR\n",
    "    print(\"=== Simple PDF OCR ===\")\n",
    "    try:\n",
    "        simple_text = simple_pdf_ocr('example.pdf')\n",
    "        print(simple_text[:500] + \"...\" if len(simple_text) > 500 else simple_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in simple OCR: {e}\")\n",
    "    \n",
    "    # Example 2: Enhanced PDF OCR with preprocessing\n",
    "    print(\"\\n=== Enhanced PDF OCR ===\")\n",
    "    try:\n",
    "        enhanced_text = enhanced_pdf_ocr('example.pdf', 'output_images')\n",
    "        print(enhanced_text[:500] + \"...\" if len(enhanced_text) > 500 else enhanced_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in enhanced OCR: {e}\")\n",
    "    \n",
    "    # Example 3: Complete PDF processing pipeline\n",
    "    print(\"\\n=== Complete PDF Processing ===\")\n",
    "    try:\n",
    "        processor = PDFOCRProcessor()\n",
    "        results = processor.process_pdf(\n",
    "            'example.pdf',\n",
    "            output_dir='ocr_output',\n",
    "            languages=['eng', 'spa']\n",
    "        )\n",
    "        print(f\"Processed {results['total_pages']} pages\")\n",
    "        print(f\"Processing time: {results['processing_time']}\")\n",
    "        print(f\"Total text length: {len(results['extracted_text'])} characters\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in complete processing: {e}\")\n",
    "    \n",
    "    # Example 4: Safe PDF OCR with error handling\n",
    "    print(\"\\n=== Safe PDF OCR ===\")\n",
    "    try:\n",
    "        safe_text = safe_pdf_ocr('example.pdf')\n",
    "        print(safe_text[:500] + \"...\" if len(safe_text) > 500 else safe_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in safe OCR: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
