{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed19fe14-01cb-4cba-bf2f-7a96c84eaa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import re\n",
    "import os, sys\n",
    "import pathlib\n",
    "from threading import Thread, Lock\n",
    "import concurrent.futures\n",
    "import time\n",
    "from collections.abc import Iterable\n",
    "import cv2\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image, ImageEnhance, ImageFilter, ImageOps\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ec27fd0-255e-45b1-af72-e58c2009b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/ngoni97/Documents/Documents/MATHEMATICS/Principia Mathematica/Principia_Mathematica [volume.I] alfred_north_whitehead x betrand_russell.pdf'\n",
    "folder = '/home/ngoni97/Documents/Documents/File Manager with ML/train_test_text_files/images_test/Original Images'\n",
    "#pages = convert_from_path(path, last_page=10, dpi=300, output_folder=folder, fmt='png')\n",
    "pages = convert_from_path(path, last_page=10, dpi=300, fmt='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eaccc73-2ece-4028-971f-38da97a4a8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PIL.PngImagePlugin.PngImageFile image mode=RGB size=2542x2894>,\n",
       " <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1962x2861>,\n",
       " <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1874x2802>,\n",
       " <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1884x2813>,\n",
       " <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1845x2781>,\n",
       " <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1845x2781>,\n",
       " <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1844x2784>,\n",
       " <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1844x2780>,\n",
       " <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1842x2779>,\n",
       " <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1843x2775>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da3b9052-2211-4f6b-86b9-ad936e820809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_image_preprocessing(image):\n",
    "    \"\"\"\n",
    "    Advanced image preprocessing for better OCR results\n",
    "    \"\"\"\n",
    "    # Convert to grayscale if needed\n",
    "    if image.mode != 'L':\n",
    "        image = image.convert('L')\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    img_array = np.array(image)\n",
    "    \n",
    "    # 1. Noise reduction\n",
    "    img_array = cv2.medianBlur(img_array, 3)\n",
    "    \n",
    "    # 2. Gaussian blur to smooth\n",
    "    img_array = cv2.GaussianBlur(img_array, (1, 1), 0)\n",
    "    \n",
    "    # 3. Adaptive thresholding for better text separation\n",
    "    img_array = cv2.adaptiveThreshold(\n",
    "        img_array, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "        cv2.THRESH_BINARY, 11, 2\n",
    "    )\n",
    "    \n",
    "    # 4. Morphological operations to clean up\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    img_array = cv2.morphologyEx(img_array, cv2.MORPH_CLOSE, kernel)\n",
    "    img_array = cv2.morphologyEx(img_array, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    # Convert back to PIL Image\n",
    "    processed_image = Image.fromarray(img_array)\n",
    "    \n",
    "    # 5. PIL-specific enhancements\n",
    "    # Enhance contrast\n",
    "    enhancer = ImageEnhance.Contrast(processed_image)\n",
    "    processed_image = enhancer.enhance(1.2)\n",
    "    \n",
    "    # Enhance sharpness\n",
    "    enhancer = ImageEnhance.Sharpness(processed_image)\n",
    "    processed_image = enhancer.enhance(1.5)\n",
    "    \n",
    "    return processed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dfd5ddb-04f8-4c5a-9bd3-b5b327840b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_images = []\n",
    "for img in pages:\n",
    "    enhanced_images.append(advanced_image_preprocessing(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1e8c842-3e56-4762-b173-7e4287660f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PIL.Image.Image image mode=L size=2542x2894>,\n",
       " <PIL.Image.Image image mode=L size=1962x2861>,\n",
       " <PIL.Image.Image image mode=L size=1874x2802>,\n",
       " <PIL.Image.Image image mode=L size=1884x2813>,\n",
       " <PIL.Image.Image image mode=L size=1845x2781>,\n",
       " <PIL.Image.Image image mode=L size=1845x2781>,\n",
       " <PIL.Image.Image image mode=L size=1844x2784>,\n",
       " <PIL.Image.Image image mode=L size=1844x2780>,\n",
       " <PIL.Image.Image image mode=L size=1842x2779>,\n",
       " <PIL.Image.Image image mode=L size=1843x2775>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhanced_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30c9643a-c4cf-43c2-8a36-98a04c7e1684",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_images[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2e56b9d-de01-4067-9265-be57b419ae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PdfDataCollector:\n",
    "    def __init__(self, file_path, pages=None, save_as_text_file=False):\n",
    "        self.file_path = file_path\n",
    "        self.pages = pages\n",
    "        self.save_as_text_file = save_as_text_file\n",
    "        \n",
    "        self.file_name = os.path.basename(self.file_path)\n",
    "        self.book_dict = {}\n",
    "        self.lock = Lock()  # Thread safety for book_dict\n",
    "        \n",
    "        # Validate file exists and is accessible\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "        if not os.access(file_path, os.R_OK):\n",
    "            raise PermissionError(f\"Cannot read file: {file_path}\")\n",
    "        \n",
    "    def remove_characters_before_tokenization(self, sentence, keep_apostrophes=False):\n",
    "        \"\"\"Clean text by removing unwanted characters\"\"\"\n",
    "        sentence = (sentence.replace('_', ' ')).replace('-', ' ')\n",
    "        \n",
    "        PATTERN = re.compile('[?|$|&|*|%|@|(|)|~]')\n",
    "        pattern = re.compile('[^a-zA-Z]') if not keep_apostrophes else re.compile('[^a-zA-Z\\']')\n",
    "        replacement = r' '\n",
    "        \n",
    "        filtered_sentence = re.sub(pattern, replacement, re.sub(PATTERN, replacement, sentence))\n",
    "        return filtered_sentence.lower()\n",
    "    \n",
    "    def advanced_image_preprocessing(self, image):\n",
    "        \"\"\"\n",
    "        Advanced image preprocessing for better OCR results\n",
    "        \"\"\"\n",
    "        # Convert to grayscale if needed\n",
    "        if image.mode != 'L':\n",
    "            image = image.convert('L')\n",
    "        \n",
    "        # Convert to numpy array\n",
    "        img_array = np.array(image)\n",
    "        \n",
    "        # 1. Noise reduction\n",
    "        img_array = cv2.medianBlur(img_array, 3)\n",
    "        \n",
    "        # 2. Gaussian blur to smooth\n",
    "        img_array = cv2.GaussianBlur(img_array, (1, 1), 0)\n",
    "        \n",
    "        # 3. Adaptive thresholding for better text separation\n",
    "        img_array = cv2.adaptiveThreshold(\n",
    "            img_array, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "            cv2.THRESH_BINARY, 11, 2\n",
    "        )\n",
    "        \n",
    "        # 4. Morphological operations to clean up\n",
    "        kernel = np.ones((1, 1), np.uint8)\n",
    "        img_array = cv2.morphologyEx(img_array, cv2.MORPH_CLOSE, kernel)\n",
    "        img_array = cv2.morphologyEx(img_array, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        # Convert back to PIL Image\n",
    "        processed_image = Image.fromarray(img_array)\n",
    "        \n",
    "        # 5. PIL-specific enhancements\n",
    "        # Enhance contrast\n",
    "        enhancer = ImageEnhance.Contrast(processed_image)\n",
    "        processed_image = enhancer.enhance(1.2)\n",
    "        \n",
    "        # Enhance sharpness\n",
    "        enhancer = ImageEnhance.Sharpness(processed_image)\n",
    "        processed_image = enhancer.enhance(1.5)\n",
    "        \n",
    "        return processed_image\n",
    "    \n",
    "    def convert_pdf_to_images(self, file_path, *, prefix='page', fmt='PNG'):\n",
    "        # original images\n",
    "        images = convert_from_path(file_path, last_page=self.pages, dpi=300, fmt='png')\n",
    "        Images = {} # enhanced images\n",
    "        print(images)\n",
    "\n",
    "        destn = '/home/ngoni97/Documents/Documents/File Manager with ML/train_test_text_files/images_test'\n",
    "        if not os.path.exists(destn):\n",
    "            os.makedirs(destn, exist_ok=True)\n",
    "        original_images = os.path.join(destn, 'Original Images')\n",
    "        if not os.path.exists(original_images):\n",
    "            os.makedirs(original_images, exist_ok=True)\n",
    "        self.enhanced_images = os.path.join(destn, 'Enhanced Images')\n",
    "        if not os.path.exists(self.enhanced_images):\n",
    "            os.makedirs(self.enhanced_images)\n",
    "\n",
    "        # creating folders corresponding to each book\n",
    "        self.saved_images_book_path = os.path.join(self.enhanced_images, os.path.basename(file_path))\n",
    "        if not os.path.exists(self.saved_images_book_path):\n",
    "            os.makedirs(self.saved_images_book_path)\n",
    "\n",
    "        for i, img in enumerate(images):\n",
    "            Images[f\"{prefix}_{i:04d}.{fmt.lower()}\"] = self.advanced_image_processing(img)\n",
    "            Img = self.advanced_image_preprocessing(img)\n",
    "            file_name = f\"{prefix}_{i:04d}.{fmt.lower()}\"\n",
    "            file_path = os.path.join(self.saved_images_book_path, file_name)\n",
    "            Img.save(file_path, fmt)\n",
    "            self.read_ocr(i, file_path) # read the single page\n",
    "\n",
    "                # Combine text from all pages\n",
    "        text = \"\"\n",
    "        for key in sorted(self.book_dict.keys()):\n",
    "            text += self.book_dict[key]\n",
    "        \n",
    "        self.Text = text\n",
    "\n",
    "        pass \n",
    "           \n",
    "    def read_ocr(self, page_num, book_path):\n",
    "        \"\"\"Read OCR text from a specific page - thread-safe version\"\"\"\n",
    "        __text = \"\"\n",
    "        doc = None\n",
    "        try:\n",
    "            # Open document with error checking\n",
    "            doc = pymupdf.open(book_path) # for one page documents\n",
    "            if doc is None:\n",
    "                return \"\"\n",
    "            \n",
    "            try:\n",
    "                text_page = doc.get_textpage_ocr(dpi=150, full=True)  # Reduced DPI for stability\n",
    "                if text_page:\n",
    "                    __text = text_page.extractTEXT()\n",
    "                    # Clean up textpage\n",
    "                    del text_page\n",
    "            except Exception:\n",
    "                pass\n",
    "                \n",
    "        except Exception:\n",
    "            pass\n",
    "        finally:\n",
    "            # Always close the document\n",
    "            if doc:\n",
    "                try:\n",
    "                    doc.close()\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        # Thread-safe dictionary update\n",
    "        with self.lock:\n",
    "            self.book_dict[page_num] = __text\n",
    "        \n",
    "        return __text\n",
    "    \n",
    "    def get_document(self, filename):\n",
    "        \"\"\"Extract text from PDF - handles both digital and OCR PDFs\"\"\"\n",
    "        self.Text = \"\"\n",
    "        \n",
    "        # Validate file before processing\n",
    "        if not os.path.exists(filename):\n",
    "            return \"\"\n",
    "        \n",
    "        # Setup directory structure\n",
    "        try:\n",
    "            self.main_folder_path = os.path.basename(os.path.dirname(os.path.dirname(filename)))\n",
    "            self.parent_directory = os.path.join(\n",
    "                '/home/ngoni97/Documents/Documents/File Manager with ML/train_test_text_files', \n",
    "                self.main_folder_path\n",
    "            )\n",
    "            \n",
    "            if not os.path.exists(self.parent_directory):\n",
    "                os.makedirs(self.parent_directory, exist_ok=True)\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        # Create text file path\n",
    "        base_name = os.path.splitext(os.path.basename(filename))[0]\n",
    "        text_file_path = os.path.join(self.parent_directory, f\"{base_name}.txt\")\n",
    "        \n",
    "        digital_pages = 0\n",
    "        ocr_pages = 0\n",
    "        doc = None\n",
    "        \n",
    "        try:\n",
    "            # Open document with explicit error handling\n",
    "            doc = pymupdf.open(filename)\n",
    "            if doc is None:\n",
    "                return \"\"\n",
    "            \n",
    "            doc_length = len(doc)\n",
    "            if doc_length == 0:\n",
    "                return \"\"\n",
    "            \n",
    "            pages_to_process = min(self.pages or doc_length, doc_length)\n",
    "            \n",
    "            # Test first few pages to determine document type (more conservative)\n",
    "            test_pages = min(3, doc_length)  # Reduced from 5 to 3\n",
    "            \n",
    "            for page_num in range(test_pages):\n",
    "                try:\n",
    "                    page = doc[page_num]\n",
    "                    if page is None:\n",
    "                        continue\n",
    "                    \n",
    "                    # Test for digital text first (safer)\n",
    "                    try:\n",
    "                        text = page.get_text()\n",
    "                        if text and text.strip():\n",
    "                            digital_pages += 1\n",
    "                            break\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                    \n",
    "                    # Only test OCR if no digital text found\n",
    "                    if digital_pages == 0:\n",
    "                        try:\n",
    "                            # Use lighter OCR test\n",
    "                            if hasattr(page, 'get_textpage_ocr'):\n",
    "                                ocr_pages += 1\n",
    "                                break\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                            \n",
    "                except Exception:\n",
    "                    continue\n",
    "            \n",
    "            # Process based on document type\n",
    "            if digital_pages > 0:\n",
    "                # Digital PDF processing (safer)\n",
    "                for page_num in range(pages_to_process):\n",
    "                    try:\n",
    "                        page = doc[page_num]\n",
    "                        if page is None:\n",
    "                            continue\n",
    "                        text = page.get_text()\n",
    "                        if text:\n",
    "                            self.Text += text\n",
    "                    except Exception:\n",
    "                        continue\n",
    "            \n",
    "            elif ocr_pages > 0:\n",
    "                # OCR processing with reduced concurrency\n",
    "                doc.close()  # Close before OCR to prevent conflicts\n",
    "                doc = None\n",
    "                self.multithreading_ocr(min(pages_to_process, 5), filename)  # Limit OCR pages\n",
    "            \n",
    "        except Exception:\n",
    "            pass\n",
    "        finally:\n",
    "            # Always close the document\n",
    "            if doc:\n",
    "                try:\n",
    "                    doc.close()\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        # Save as text file if requested\n",
    "        if self.save_as_text_file and self.Text:\n",
    "            try:\n",
    "                with open(text_file_path, 'w', encoding='utf-8') as text_file:\n",
    "                    text_file.write(self.Text)\n",
    "            except Exception:\n",
    "                pass\n",
    "        \n",
    "        return self.Text\n",
    "    \n",
    "    def returnText(self):\n",
    "        \"\"\"Return both raw and cleaned text\"\"\"\n",
    "        self._text = self.get_document(self.file_path)\n",
    "        self.__text = self.remove_characters_before_tokenization(self._text)\n",
    "        return self._text, self.__text\n",
    "    \n",
    "    def get_bookmarks(self, filepath):\n",
    "        \"\"\"Extract bookmarks from PDF\"\"\"\n",
    "        self.bookmarks = {}\n",
    "        try:\n",
    "            with pymupdf.open(filepath) as file:\n",
    "                toc = file.get_toc()\n",
    "                for level, title, page in toc:\n",
    "                    self.bookmarks[page] = title\n",
    "        except Exception:\n",
    "            pass\n",
    "        return self.bookmarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03a0ed07-b42c-4254-b87c-001c5c6bd882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = '/home/ngoni97/Documents/MATHEMATICS/Principia Mathematica/Principia_Mathematica [volume.I] alfred_north_whitehead x betrand_russell.pdf'\n",
    "test = PdfDataCollector(path, 10)\n",
    "Text, text = test.returnText()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7702373d-59e5-44e0-b50d-fb818292555b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fda587e-e53a-4f49-a281-682780726915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ceff00-71ea-4e48-9c10-266412ed40a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d941cee-2925-403c-9bf9-3dab29affcd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ab31f-1c59-4efa-83f3-7e9d774c05fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f20031-f2d8-403d-a2e1-34ff2d84e476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d113d18d-d5e0-470c-ac80-b6798e632b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd8d545-6b5d-4556-834b-3373f81ee205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d9470e-a260-40a3-ab1f-88a1dfa1275e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20161cd0-8932-44e2-b358-8a9d7d9ea39b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
